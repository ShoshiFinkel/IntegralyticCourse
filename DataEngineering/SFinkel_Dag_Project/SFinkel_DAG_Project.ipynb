{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from functools import reduce\n",
    "import datetime as dt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to extract the data.\n",
    "def extract_data(file_path, chunksize = 10**5):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calaulate the trip duration in minutes.\n",
    "def calculate_trip_duration_in_minutes(chunks):\n",
    "    for chunk in chunks:\n",
    "        chunk = chunk.dropna()\n",
    "        chunk['trip_duration_minutes'] = chunk['trip_duration'] / 60\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a rush hour column.\n",
    "def create_rush_hour_feature(chunks):\n",
    "    start_time = 7\n",
    "    end_time = 9\n",
    "    for chunk in chunks:\n",
    "        chunk = chunk.loc[(chunk['pickup_datetime']!=0)&(chunk['dropoff_datetime']!=0)]\n",
    "        rush_hour_start = pd.to_datetime(start_time)\n",
    "        rush_hour_end = pd.to_datetime(end_time)\n",
    "        chunk['is_rush_hour'] = (pd.to_datetime(chunk['pickup_datetime'] )>= rush_hour_start) & (pd.to_datetime(chunk['dropoff_datetime'] )<= rush_hour_end)\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to extract the day of the week.\n",
    "def extract_day_of_week(chunks):\n",
    "    for chunk in chunks:\n",
    "        chunk['day_of_week'] = pd.to_datetime(chunk['pickup_datetime']).dt.weekday\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to filter out unrealistic trips.\n",
    "def filter_out_unrealistic_trips(chunks):\n",
    "    for chunk in chunks:\n",
    "        min_trip_duration = 1\n",
    "        max_trip_duration = 24 * 60\n",
    "        chunk = chunk[(chunk['trip_duration'] >= min_trip_duration) & (chunk['trip_duration'] <= max_trip_duration)]\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to one hot encode the day of week column.\n",
    "def one_hot_encode_day_of_week(chunks):\n",
    "    for chunk in chunks:\n",
    "        chunk = pd.get_dummies(chunk, columns = ['day_of_week'], prefix='day_of_week')\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load the transformed data into a new file.\n",
    "def load_data(chunks, destination='transformed_data.json'):\n",
    "    for chunk in chunks:\n",
    "        if destination.endswith('.csv'):\n",
    "            chunk.to_csv(destination)\n",
    "        elif destination.endswith('.db'):\n",
    "            chunk.to_sql('trips',destination)\n",
    "        elif destination.endswith('.json'):\n",
    "            chunk.to_json(destination)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid destination file type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a compose function\n",
    "def compose(*functions):\n",
    "    return reduce(lambda f, g: lambda x: g(f(x)), functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The user\\AppData\\Local\\Temp\\ipykernel_45292\\456933126.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk['trip_duration_minutes'] = chunk['trip_duration'] / 60\n"
     ]
    }
   ],
   "source": [
    "# Execute the compose.\n",
    "composed = compose(extract_data, calculate_trip_duration_in_minutes, create_rush_hour_feature, extract_day_of_week, filter_out_unrealistic_trips, one_hot_encode_day_of_week, load_data)\n",
    "composed('train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
